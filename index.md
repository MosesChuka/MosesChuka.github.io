
<!-- ---
layout: default
title: Okonkwo Moses Chukwuka
description: Moses Chukwuka's website
---  -->

<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
<link href="/static/css/styles.css" rel="stylesheet">

<button class="theme-toggle" onclick="toggleTheme()" id="themeToggle">🌙 Dark</button>
<button style='padding: 5px 5px; border-radius: 6px;' onclick="toggleLanguage()">English / 中文)</button>

<div class="container" id="en">
<header class="header">
<h2>Okonkwo Moses Chukwuka</h2>
<img src="/static/MosesChuka-img2.jpg" alt="Okonkwo Moses Chukwuka" class="profile-img"/>
</header>

<section class="about">
<p>I am a PhD student with interest in Computer Vision and Perception for Autonomous Systems at Zhejiang University, School of Electrical Engineering, Hangzhou, Zhejiang, China. Currently, I am looking into improving the environmental perception of robots.</p>
<p>Prior to ZJU, I earned a Master's degree in Electrical Engineering with focus on Robotics and AI from Shenyang University of Technology, and a Bachelor's degree in Electronic Information Engineering from Xiangtan University.</p>
<p>Beyond work, I enjoy having interesting conversation with people, walking and reading.</p>

<p><strong>Email:</strong> chukwukaokonkwo8@gmail.com | chukwukaokonkwo@zju.edu.cn</p>
<div style='align-items: center; display:block;' class="links">
    <a href="/static/Okonkwo%20Moses%20Chukwuka%20ZJU-CV.pdf">CV</a> 
    <a href="https://www.researchgate.net/profile/Moses-Okonkwo">ResearchGate</a> 
    <a href="https://www.facebook.com/Chukwuka.0konkwo1">Facebook</a>
</div>

</section>



<section class="updates">
<h2>Recent Updates</h2>
<ul>
<li><strong>2025-Present</strong> – Visiting Student at WestLake University and AI at Zhejiang University.</li>
<li><strong>2024-Present</strong> – PhD in Autonomous Robotics and AI at Zhejiang University.</li>
<li><strong>2024</strong> – Published: RDSP-SLAM: Robust Object-Aware SLAM based on Deep Shape Priors. IEEE ACCESS.</li>
</ul>
</section>

<section class="research">
<h2>Research</h2>


<div class="research-item">
<div class="research-content">
<h3><a href="http://dx.doi.org/10.1109/ACCESS.2024.3368859">RDSP-SLAM: Robust Object-Aware SLAM based on Deep Shape Priors</a></h3>
<p><em>Moses Chukwuka Okonkwo, Junyou Yang, Yizhen Sun, Guang Yang, Fausto Pedro García Márquez</em><br><strong>IEEE ACCESS (2024)</strong></p>
</div>
</div>
</section>

<section class="projects">
<h2>Projects</h2>
<div class="project-item">
<h3>Robust Keyframe segmentation of visual Object-SLAM Based on Deepshape priors (ORBSLAM2, DeepSDF, YOLOv8/RTM-Det)</h3>
<p><em>2023, MSc Project (in-progress)</em></p>
</div>
<div class="project-item">
<h3>Trajectory Estimation on Visual Stream Images Using Agro-Nav</h3>
<p><em>2022</em></p>
</div>
</section>

<section class="work-experience">
<h2>Work Experience</h2>
<div class="work-item">
<div class="work-content">
<h3>Internship, Northeast University Perception Research Lab</h3>
<p>Training of crop row detection deep learning models; Training of deep learning models for farm scene panoptic segmentation; Deployment of deep learning models using Pytorch and ROS for robust visual navigation of Agricultural Robots; Visual Navigation: ORB-SLAM(2/3).<br><em>2023-Present</em></p>
</div>
</div>
<div class="work-item">
<div class="work-content">
<h3>Xiangtan University Summer Engineering Boot Camp</h3>
<p>Embedded Systems and Programming.<br><em>2019</em></p>
</div>
</div>
<div class="work-item">
<div class="work-content">
<h3>Xiangtan Shenzhou Special Cables Co., Ltd.</h3>
<p>Xiangtan City, Hunan Province, P.R. China.<br><em>2018</em></p>
</div>
</div>
</section>

<section class="education">
<h2>Education</h2>
<div class="education-item">
<div class="education-content">
<h3>Zhejiang University</h3>
<p>PhD in Autonomous Robotics and AI<br><em>2024-Present</em></p>
</div>
</div>
<div class="education-item">
<div class="education-content">
<h3>Shenyang University of Technology</h3>
<p>Master's in Electrical Engineering with focus on Robotics and AI<br><em>2021-2024</em></p>
</div>
</div>
<div class="education-item">
<div class="education-content">
<h3>Xiangtan University</h3>
<p>Bachelor of Engineering in Electronic Information Engineering<br><em>2017-2021</em></p>
</div>
</div>
<div class="education-item">
<div class="education-content">
<h3>International Exchange College, Xiangtan University</h3>
<p>Chinese Language Proficiency, HSK4<br><em>2016-2017</em></p>
</div>
</div>
</section>

<section class="teaching-service">
<h2>Service</h2>
<ul>
<li>Graduate Student Research Assistant (Navigation, Positioning, and Wireless Communication), <em>2018-2021</em></li>
</ul>
</section>

<footer>© Okonkwo Moses Chukwuka | Last updated: August 2025</footer>
</div>

<div class="container" id="zh" style="display:none">
<header class="header">
<h1>Okonkwo Moses Chukwuka</h1>
<img src="/static/MosesChuka-img.HEIC" alt="Okonkwo Moses Chukwuka" class="profile-img"/>
</header>

<section class="about">
<p>我是浙江大学（世界大学排名第47位）自主机器人与人工智能博士生，中国浙江杭州。</p>
<p>在浙大之前，我从沈阳工业大学获得电气工程硕士学位，重点关注机器人和人工智能，从湘潭大学获得电子信息工程学士学位。</p>
<p>工作之外，我喜欢摄影和视频制作，打篮球，以及阅读。</p>

<div class="links">
<a href="/static/Okonkwo%20Moses%20Chukwuka%20ZJU-CV.pdf">简历</a> |
<a href="https://www.researchgate.net/profile/Moses-Okonkwo">ResearchGate</a> |
<a href="https://www.facebook.com/ChukwukaOkonkwo">Facebook</a>
</div>
</section>

<section class="contact">
<h2>联系方式</h2>
<p><strong>电子邮件:</strong> chukwukaokonkwo8@gmail.com</p>
<p><strong>电话:</strong> 0086-151-972-70-103; 0086-177-435-075-22</p>
<div class="links">
<a href="https://www.facebook.com/ChukwukaOkonkwo">Facebook</a> |
<a href="https://www.researchgate.net/profile/Moses-Okonkwo">ResearchGate</a>
</div>
</section>

<section class="updates">
<h2>最近更新</h2>
<ul>
<li><strong>2024-至今</strong> – 浙江大学自主机器人与人工智能博士。</li>
<li><strong>2024</strong> – 论文审稿中：提升稳定性和安全性：叉车轨迹的新型多约束模型预测控制方法。IET Cyber-Systems and Robotics。</li>
<li><strong>2024</strong> – 发表：RDSP-SLAM：基于深度形状先验的鲁棒物体感知SLAM。IEEE ACCESS。</li>
<li><strong>2023-至今</strong> – 东北大学感知研究实验室实习。</li>
<li><strong>2022</strong> – 发表：轮式助行机器人安全合规非接触交互方法。Computational Intelligence and Neuroscience Journals。</li>
</ul>
</section>

<section class="research">
<h2>研究</h2>
<div class="research-item">
<div class="research-content">
<h3>提升稳定性和安全性：叉车轨迹的新型多约束模型预测控制方法</h3>
<p><em>Yizhen Sun, Junyou Yang, Donghui Zhao, Moses Chukwuka Okonkwo, Jianmin Zhang, Shuoyu Wang, Yang Liu</em><br><strong>IET Cyber-Systems and Robotics (审稿中, 2024)</strong></p>
</div>
</div>
<div class="research-item">
<div class="research-content">
<h3>RDSP-SLAM：基于深度形状先验的鲁棒物体感知SLAM</h3>
<p><em>Moses Chukwuka Okonkwo, Junyou Yang, Yizhen Sun, Guang Yang, Fausto Pedro García Márquez</em><br><strong>IEEE ACCESS (2024)</strong><br><a href="http://dx.doi.org/10.1109/ACCESS.2024.3368859">链接</a></p>
</div>
</div>
<div class="research-item">
<div class="research-content">
<h3>轮式助行机器人安全合规非接触交互方法</h3>
<p><em>Donghui Zhao, Wei Wang, Moses Chukwuka Okonkwo, Zihao Yang, Junyou Yang, Houde Liu</em><br><strong>Computational Intelligence and Neuroscience Journals (2022)</strong><br><a href="http://dx.doi.org/10.1155/2022/3033920">链接</a></p>
</div>
</div>
<div class="research-item">
<div class="research-content">
<h3>基于到达时间测量的异步源定位新型方法</h3>
<p><em>Huijie Zhu, Sheng Liu, Wei Xu, Zhiqiang Yao, Moses Chukwuka Okonkwo, Zheng Peng</em><br><strong>International Journal of Distributed Sensor Networks (2020)</strong><br><a href="http://dx.doi.org/10.1177/15501477211053706">链接</a></p>
</div>
</div>
<div class="research-item">
<div class="research-content">
<h3>移动通信信号位置源选择方法研究</h3>
<p><em>Huijie Zhu, Wei Xu, Yalou Sang, Zhiqiang Yao, Limei Liu, Moses Chukwuka Okonkwo</em><br><strong>IEEE/ICACT2021 (2020)</strong></p>
</div>
</div>
</section>

<section class="projects">
<h2>项目</h2>
<div class="project-item">
<h3>基于深度形状先验的视觉物体SLAM鲁棒关键帧分割 (ORBSLAM2, DeepSDF, YOLOv8/RTM-Det)</h3>
<p><em>2023, 硕士项目 (进行中)</em></p>
</div>
<div class="project-item">
<h3>基于神经网络的室内物体实时识别 (Yolov5)</h3>
<p><em>2022</em></p>
</div>
<div class="project-item">
<h3>基于STM32的PID控制电机移动车</h3>
<p><em>2021, 本科项目</em></p>
</div>
<div class="project-item">
<h3>伺服电机PID速度控制</h3>
<p><em>2021</em></p>
</div>
<div class="project-item">
<h3>使用STM32嵌入式系统显示IMU和GPS传感器数据</h3>
<p><em>2020</em></p>
</div>
<div class="project-item">
<h3>聋人声音检测阅读眼镜</h3>
<p><em>2020, 团队</em></p>
</div>
<div class="project-item">
<h3>基于时间的步进电机控制用于穿衣机器人</h3>
<p><em>2020</em></p>
</div>
<div class="project-item">
<h3>基于光敏电阻的51 McU线跟踪移动车</h3>
<p><em>2019</em></p>
</div>
<div class="project-item">
<h3>使用8051 McU的振荡器时钟和闹钟</h3>
<p><em>2019</em></p>
</div>
</section>

<section class="work-experience">
<h2>工作经验</h2>
<div class="work-item">
<div class="work-content">
<h3>东北大学感知研究实验室实习</h3>
<p>作物行检测深度学习模型训练；农场场景全景分割深度学习模型训练；使用Pytorch和ROS部署深度学习模型用于农业机器人的鲁棒视觉导航；视觉导航：ORB-SLAM(2/3)。<br><em>2023-至今</em></p>
</div>
</div>
<div class="work-item">
<div class="work-content">
<h3>湘潭大学夏季工程训练营</h3>
<p>嵌入式系统和编程。<br><em>2019</em></p>
</div>
</div>
<div class="work-item">
<div class="work-content">
<h3>湘潭神舟特种电缆有限公司</h3>
<p>湖南省湘潭市，中国。<br><em>2018</em></p>
</div>
</div>
</section>

<section class="education">
<h2>教育背景</h2>
<div class="education-item">
<div class="education-content">
<h3>浙江大学</h3>
<p>自主机器人与人工智能博士<br><em>2024-至今</em></p>
</div>
</div>
<div class="education-item">
<div class="education-content">
<h3>沈阳工业大学</h3>
<p>电气工程硕士，重点机器人和人工智能<br><em>2021-2024</em></p>
</div>
</div>
<div class="education-item">
<div class="education-content">
<h3>湘潭大学</h3>
<p>电子信息工程学士<br><em>2017-2021</em></p>
</div>
</div>
<div class="education-item">
<div class="education-content">
<h3>湘潭大学国际交流学院</h3>
<p>汉语水平考试HSK4<br><em>2016-2017</em></p>
</div>
</div>
</section>

<section class="teaching-service">
<h2>服务</h2>
<ul>
<li>成员，Texas Instrument Research and Development Lab, <em>2018-2021</em></li>
<li>研究生研究助理（导航、定位和无线通信）, <em>2018-2021</em></li>
</ul>
</section>

<footer>© Okonkwo Moses Chukwuka | 最后更新: 2025年8月</footer>
</div>

<script>
let lang = 'en';

// Theme toggle functionality
function toggleTheme() {
  const body = document.body;
  const themeToggle = document.getElementById('themeToggle');
  
  if (body.classList.contains('light-mode')) {
    body.classList.remove('light-mode');
    themeToggle.textContent = '🌙';
    themeToggle.classList.remove('light');
    localStorage.setItem('theme', 'dark');
  } else {
    body.classList.add('light-mode');
    themeToggle.textContent = '☀️';
    themeToggle.classList.add('light');
    localStorage.setItem('theme', 'light');
  }
}

// Language toggle functionality
function toggleLanguage() {
  lang = lang === 'en' ? 'zh' : 'en';
  document.getElementById('en').style.display = lang === 'en' ? 'block' : 'none';
  document.getElementById('zh').style.display = lang === 'zh' ? 'block' : 'none';
}

// Load saved theme on page load
document.addEventListener('DOMContentLoaded', function() {
  const savedTheme = localStorage.getItem('theme');
  const themeToggle = document.getElementById('themeToggle');
  
  if (savedTheme === 'light') {
    document.body.classList.add('light-mode');
    themeToggle.textContent = '☀️';
    themeToggle.classList.add('light');
  }
});
</script>
